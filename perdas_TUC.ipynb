{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o diretório padrão\n",
    "caminho = os.chdir('C:\\\\Users\\\\anand\\\\Documents\\\\BT\\\\input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TUC20', 'TUC21', 'TUC22', 'TUC23', 'TUC24']\n"
     ]
    }
   ],
   "source": [
    "#Salvando os nomes dos arquivos em uma lista para serem usados posteriormente\n",
    "lista_arquivos = os.listdir(caminho)\n",
    "nomes_arquivos = []\n",
    "for arquivo in lista_arquivos:\n",
    "  if arquivo.endswith('.json'):\n",
    "    arquivo_semext = arquivo.replace('.json', '')\n",
    "    nomes_arquivos.append(arquivo_semext)\n",
    "print(nomes_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os arquivos\n",
    "\n",
    "todos_arquivos = []\n",
    "diretorio = r'C:\\Users\\anand\\Documents\\BT\\\\input'\n",
    "for arquivo in os.listdir(diretorio):\n",
    "        caminho_arquivo = os.path.join(diretorio, arquivo)\n",
    "        with open(caminho_arquivo, 'r') as file:\n",
    "            dados = json.load(file)\n",
    "            todos_arquivos.append(dados)    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudando a estrutura dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificando a estrutura do arquivo\n",
    "print(todos_arquivos[0].keys())\n",
    "print(todos_arquivos[0]['objects'].keys())\n",
    "print(todos_arquivos[0]['objects']['11893575734DC000'].keys())\n",
    "print(todos_arquivos[0]['objects']['11893575734DC000']['points'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dicionário provisório com a chave do primeiro arquivo, para identificar a estrutura e extrair os kpis \n",
    "dicionario = todos_arquivos[0]['objects']['11893575734DC000']['points'] \n",
    "dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calc-LossUnavailability.5min', 'Calc-DeltaOverIrrad.5min', 'Calc-DeltaIrrad.5min', 'Calc-DeltaTemp.5min', 'Calc-DeltaAlbedo.5min', 'Calc-ExpectedDC.5min', 'Calc-LossSoiling.5min', 'Calc-LossShading.5min', 'Calc-LossStringPerf.5min', 'Calc-LossEfficiency.5min', 'Calc-EnergyDC.5min', 'Calc-LossClipping.5min', 'Calc-LossClippingTemp.5min', 'Calc-LossGridLimitation.5min', 'Calc-LossCurtailment.5min', 'Calc-LossInvToSPE.5min', 'Waterfall-DeliveredEnergy.5min']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acrescentando kpis do dicionário em uma lista\n",
    "kpis = []\n",
    "for key in dicionario.keys():\n",
    "  if not key.startswith('Waterfall') and not key.startswith('Calc-Error') and not key.startswith('Calc-LossDeviation') and not key.startswith('Calc-SPEGeneration'): #Removendo kpis desnecessários\n",
    "    if key not in kpis:\n",
    "      kpis.append(key)\n",
    "\n",
    "kpis.append('Waterfall-DeliveredEnergy.5min') #adiciona o único campo \"waterfall\" necessário\n",
    "print(kpis)\n",
    "len(kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes com valores separados por SPE e datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11893575734DC000']\n",
      "TUC20 salvo!\n",
      "['11893575734DC001']\n",
      "TUC21 salvo!\n",
      "['11893575734DC002']\n",
      "TUC22 salvo!\n",
      "['11893575734DC003']\n",
      "TUC23 salvo!\n",
      "['11893575734DC004']\n",
      "TUC24 salvo!\n"
     ]
    }
   ],
   "source": [
    "#Criando um dataframe para cada arquivo .json importado\n",
    "num = 0\n",
    "for arquivo in todos_arquivos:\n",
    "  obj_key = list(arquivo['objects'].keys()) #Identificando a object key de cada arquivo\n",
    "  print(obj_key)\n",
    "  dicionario = arquivo['objects'][obj_key[0]]['points'] #Criando um dicionário para cada arquivo a partir da object key identificada\n",
    "  kpi_1 = kpis[0]\n",
    "  df1 = pd.DataFrame(dicionario[kpi_1][0]['timeSeries']) #Criando o primeiro dataframe com os kpis, onde será mantida a coluna de tempo\n",
    "  df1 = df1.drop(columns=['t_local','q'])\n",
    "  df1 = df1.rename(columns={'t':'Time', 'v': kpis[0]})\n",
    "  df1 = df1.set_index('Time') #Definindo a coluna 'Time' como index\n",
    "  for n in range (1, len(kpis)): #Criando os demais dataframes, com somente a coluna 'v'\n",
    "    if kpis[n] != kpis[0]:\n",
    "      kpi_n = kpis[n]\n",
    "      df2 = pd.DataFrame(dicionario[kpi_n][0]['timeSeries'])\n",
    "      df2 = df2.drop(columns=['t_local','q'])\n",
    "      df2 = df2.rename(columns={'t':'Time', 'v': kpis[n]})\n",
    "      df2 = df2.set_index('Time') #Definindo a coluna 'Time' como index\n",
    "      df1 = pd.merge(df1,df2, left_index=True, right_index=True, how='inner') #Unindo todos os dataframes ao primeiro, a partir do index\n",
    "  df1.head()\n",
    "  df1['Meta'] = df1['Calc-ExpectedDC.5min'] - (df1['Calc-DeltaAlbedo.5min'] + df1['Calc-DeltaTemp.5min'] + df1['Calc-DeltaIrrad.5min'])\n",
    "  df1['Date'] = df1.index\n",
    "  df1['Date'] = pd.to_datetime(df1['Date'], unit='ms')\n",
    "  df1 = df1.rename(columns={'Calc-EnergyDC.5min':'Calc-EnergyAC.5min'})\n",
    "  df_name = nomes_arquivos[num] #Nomeando os arquivos a partir da lista com nome dos .jsons importados\n",
    "  num+=1\n",
    "  #Renomeando as colunas\n",
    "  df1.columns = [\n",
    "      coluna.replace('Calc-', '').replace('.5min', '').replace('Waterfall-', '')\n",
    "      for coluna in df1.columns\n",
    "  ]\n",
    "  #Salvando os dataframes\n",
    "  df1.to_excel('C:\\\\Users\\\\anand\\\\Documents\\\\BT\\\\output\\\\consol_SPE_excel\\\\' + 'consolidated_' + df_name +'.xlsx', engine ='xlsxwriter') \n",
    "  print(f'{df_name} salvo!')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LossUnavailability</th>\n",
       "      <th>DeltaOverIrrad</th>\n",
       "      <th>DeltaIrrad</th>\n",
       "      <th>DeltaTemp</th>\n",
       "      <th>DeltaAlbedo</th>\n",
       "      <th>ExpectedDC</th>\n",
       "      <th>LossSoiling</th>\n",
       "      <th>LossShading</th>\n",
       "      <th>LossStringPerf</th>\n",
       "      <th>LossEfficiency</th>\n",
       "      <th>EnergyAC</th>\n",
       "      <th>LossClipping</th>\n",
       "      <th>LossClippingTemp</th>\n",
       "      <th>LossGridLimitation</th>\n",
       "      <th>LossCurtailment</th>\n",
       "      <th>LossInvToSPE</th>\n",
       "      <th>DeliveredEnergy</th>\n",
       "      <th>Meta</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730430000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730430300000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-01 03:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730430600000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-01 03:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730430900000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-01 03:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730431200000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-01 03:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LossUnavailability  DeltaOverIrrad  DeltaIrrad  DeltaTemp  \\\n",
       "Time                                                                       \n",
       "1730430000000                 0.0             0.0         0.0        0.0   \n",
       "1730430300000                 0.0             0.0         0.0        0.0   \n",
       "1730430600000                 0.0             0.0         0.0        0.0   \n",
       "1730430900000                 0.0             0.0         0.0        0.0   \n",
       "1730431200000                 0.0             0.0         0.0        0.0   \n",
       "\n",
       "               DeltaAlbedo  ExpectedDC  LossSoiling  LossShading  \\\n",
       "Time                                                               \n",
       "1730430000000          0.0         0.0          0.0          0.0   \n",
       "1730430300000          0.0         0.0          0.0          0.0   \n",
       "1730430600000          0.0         0.0          0.0          0.0   \n",
       "1730430900000          0.0         0.0          0.0          0.0   \n",
       "1730431200000          0.0         0.0          0.0          0.0   \n",
       "\n",
       "               LossStringPerf  LossEfficiency  EnergyAC  LossClipping  \\\n",
       "Time                                                                    \n",
       "1730430000000             0.0             0.0       0.0           0.0   \n",
       "1730430300000             0.0             0.0       0.0           0.0   \n",
       "1730430600000             0.0             0.0       0.0           0.0   \n",
       "1730430900000             0.0             0.0       0.0           0.0   \n",
       "1730431200000             0.0             0.0       0.0           0.0   \n",
       "\n",
       "               LossClippingTemp  LossGridLimitation  LossCurtailment  \\\n",
       "Time                                                                   \n",
       "1730430000000                 0                 0.0              0.0   \n",
       "1730430300000                 0                 0.0              0.0   \n",
       "1730430600000                 0                 0.0              0.0   \n",
       "1730430900000                 0                 0.0              0.0   \n",
       "1730431200000                 0                 0.0              0.0   \n",
       "\n",
       "               LossInvToSPE  DeliveredEnergy  Meta                Date  \n",
       "Time                                                                    \n",
       "1730430000000           0.0              0.0   0.0 2024-11-01 03:00:00  \n",
       "1730430300000           0.0              0.0   0.0 2024-11-01 03:05:00  \n",
       "1730430600000           0.0              0.0   0.0 2024-11-01 03:10:00  \n",
       "1730430900000           0.0              0.0   0.0 2024-11-01 03:15:00  \n",
       "1730431200000           0.0              0.0   0.0 2024-11-01 03:20:00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TUC20', 'TUC21', 'TUC22', 'TUC23', 'TUC24']\n"
     ]
    }
   ],
   "source": [
    "#Salvando os nomes dos arquivos em uma lista para serem usados posteriormente\n",
    "caminho_dataframes = os.chdir('C:\\\\Users\\\\anand\\\\Documents\\\\BT\\\\output\\\\consol_SPE_excel')\n",
    "lista_dataframes = os.listdir(caminho_dataframes)\n",
    "nomes_dataframes = []\n",
    "for dataframe in lista_dataframes:\n",
    "  if dataframe.endswith('.xlsx'):\n",
    "    dataframe_semext = dataframe.replace('consolidated_', '')\n",
    "    dataframe_semext = dataframe_semext.replace('.xlsx', '')\n",
    "    nomes_dataframes.append(dataframe_semext)\n",
    "print(nomes_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe único com valores acumulados de todas SPEs e separados por datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolidated_TUC20.xlsx\n",
      "consolidated_TUC21.xlsx\n",
      "consolidated_TUC22.xlsx\n",
      "consolidated_TUC23.xlsx\n",
      "consolidated_TUC24.xlsx\n",
      "DataFrame acumulado:\n"
     ]
    }
   ],
   "source": [
    "df_diario = pd.DataFrame()\n",
    "num = 0\n",
    "for excel in os.listdir(caminho_dataframes):\n",
    "    print(excel)\n",
    "    caminho_excel = os.path.join(caminho_dataframes, excel)\n",
    "    if excel.endswith('.xlsx'):\n",
    "        dataframe = pd.read_excel(caminho_excel, sheet_name=None)\n",
    "        dataframe = dataframe.drop(columns='Date')\n",
    "        df_diario_name = nomes_arquivos[num]  \n",
    "        dataframe['SPE'] = df_diario_name    \n",
    "    if df_diario.empty:\n",
    "        df_diario = dataframe\n",
    "    else:\n",
    "        df_diario = pd.concat([df_diario, dataframe])\n",
    "    num +=1\n",
    "\n",
    "print(\"DataFrame acumulado:\")\n",
    "df_diario.head()\n",
    "df_diario['Date'] = df_diario['Time']\n",
    "df_diario['Date'] = pd.to_datetime(df_diario['Date'], unit='ms')\n",
    "df_diario['Deviation'] = df_diario['DeliveredEnergy'] + df_diario['LossClipping'] + df_diario['LossClippingTemp'] + df_diario['LossGridLimitation'] + df_diario['LossCurtailment'] + df_diario['LossUnavailability'] - df_diario['EnergyAC']\n",
    "df_diario['LossEfficiency'] = -df_diario['EnergyAC'] + df_diario['ExpectedDC'] - df_diario['LossSoiling'] - df_diario['LossShading'] - df_diario['LossStringPerf'] \n",
    "df_diario['Resource'] = df_diario['DeltaIrrad'] + df_diario['DeltaTemp'] + df_diario['DeltaAlbedo']\n",
    "df_diario['LossDC'] = df_diario['LossSoiling'] + df_diario['LossShading'] + df_diario['LossStringPerf'] + df_diario['LossEfficiency']\n",
    "df_diario['LossAC'] = df_diario['LossClipping'] + df_diario['LossClippingTemp'] + df_diario['LossGridLimitation'] + df_diario['LossCurtailment'] + df_diario['LossUnavailability']\n",
    "df_diario['NoCurtailment'] = df_diario['DeliveredEnergy'] + df_diario['LossCurtailment']\n",
    "df_diario.to_excel('C:\\\\Users\\\\anand\\\\Documents\\\\BT\\\\output\\\\'+ 'diario'+'.xlsx', engine ='xlsxwriter') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419577.1026332099\n",
      "419577.1026332099\n"
     ]
    }
   ],
   "source": [
    "print(df_diario['LossDC'].sum())\n",
    "print((df_diario['LossSoiling'] + df_diario['LossShading'] + df_diario['LossStringPerf'] + df_diario['LossEfficiency']).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
